{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from functions import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has length 454 and consist of 12 unique characters.\n"
     ]
    }
   ],
   "source": [
    "filename = 'input.txt'\n",
    "#filename = 'wodehouse_right_ho_jeeves.txt'\n",
    "data_raw = open(filename, 'r').read() # should be simple plain text file\n",
    "#data_raw = data_raw.lower()\n",
    "#data_raw = data_raw[0:10009]\n",
    "\n",
    "table = str.maketrans(dict.fromkeys('ï»¿_\\xa0¡§¨©ªÃ´'))\n",
    "data_raw = data_raw.translate(table)\n",
    "\n",
    "data, vocab_size, idx_to_char, char_to_idx = data_from_text(data_raw)\n",
    "\n",
    "#print( 'data_one_hot shape: ', data_one_hot.shape)\n",
    "#data_raw\n",
    "#char_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 25 # this is how much of the data we sample before updating the params\n",
    "hidden_size = 100 # size of the hidden state vector\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    " \n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyLSTM(\n",
       "  (lstm): LSTM(12, 100)\n",
       "  (linear): Linear(in_features=100, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyLSTM(vocab_size, hidden_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 58.174476623535156\n",
      "epoch: 2, loss: 56.10284423828125\n",
      "epoch: 3, loss: 54.543941497802734\n",
      "epoch: 4, loss: 50.54198455810547\n",
      "epoch: 5, loss: 39.71495819091797\n",
      "epoch: 6, loss: 32.07414627075195\n",
      "epoch: 7, loss: 21.78575325012207\n",
      "epoch: 8, loss: 14.431146621704102\n",
      "epoch: 9, loss: 8.241966247558594\n",
      "epoch: 10, loss: 4.934496879577637\n",
      "epoch: 11, loss: 3.306635856628418\n",
      "epoch: 12, loss: 2.4206337928771973\n",
      "epoch: 13, loss: 1.88084077835083\n",
      "epoch: 14, loss: 1.5358505249023438\n",
      "epoch: 15, loss: 1.289149284362793\n",
      "epoch: 16, loss: 1.111598014831543\n",
      "epoch: 17, loss: 0.9770164489746094\n",
      "epoch: 18, loss: 0.8730382919311523\n",
      "epoch: 19, loss: 0.7904462814331055\n",
      "epoch: 20, loss: 0.7235379219055176\n",
      "epoch: 21, loss: 0.6684017181396484\n",
      "epoch: 22, loss: 0.6223416328430176\n",
      "epoch: 23, loss: 0.5834407806396484\n",
      "epoch: 24, loss: 0.5502891540527344\n",
      "epoch: 25, loss: 0.5217976570129395\n",
      "epoch: 26, loss: 0.49711179733276367\n",
      "epoch: 27, loss: 0.4755516052246094\n",
      "epoch: 28, loss: 0.4565868377685547\n",
      "epoch: 29, loss: 0.4397926330566406\n",
      "epoch: 30, loss: 0.42482471466064453\n",
      "epoch: 31, loss: 0.4114093780517578\n",
      "epoch: 32, loss: 0.39931726455688477\n",
      "epoch: 33, loss: 0.38836240768432617\n",
      "epoch: 34, loss: 0.37838268280029297\n",
      "epoch: 35, loss: 0.3692483901977539\n",
      "epoch: 36, loss: 0.36084604263305664\n",
      "epoch: 37, loss: 0.35307741165161133\n",
      "epoch: 38, loss: 0.34586524963378906\n",
      "epoch: 39, loss: 0.3391451835632324\n",
      "epoch: 40, loss: 0.33286285400390625\n",
      "epoch: 41, loss: 0.3269777297973633\n",
      "epoch: 42, loss: 0.3214597702026367\n",
      "epoch: 43, loss: 0.3162803649902344\n",
      "epoch: 44, loss: 0.3114180564880371\n",
      "epoch: 45, loss: 0.306854248046875\n",
      "epoch: 46, loss: 0.30257511138916016\n",
      "epoch: 47, loss: 0.2985539436340332\n",
      "epoch: 48, loss: 0.29477739334106445\n",
      "epoch: 49, loss: 0.29123640060424805\n"
     ]
    }
   ],
   "source": [
    "# initialize parameters\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train(model, optimizer, loss_fn, num_epochs, data, seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.reset_states()\n",
    "\n",
    "seed_string = 'm'\n",
    "sample = generate_sample(model, 1000, [char_to_idx[i] for i in seed_string])\n",
    "''.join([idx_to_char[i] for i in sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is kemal. my name is \n"
     ]
    }
   ],
   "source": [
    "def print_sample(model, seed_string, length):\n",
    "    sample = generate_sample(model, length, [char_to_idx[i] for i in seed_string])\n",
    "    sample = ''.join([idx_to_char[i] for i in sample])\n",
    "    print(sample)\n",
    "\n",
    "model.reset_states()\n",
    "print_sample(model, 'm', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
